---
date: 2024-01-20 17:43:59.572232-07:00
description: "\u05D4\u05D5\u05E8\u05D3\u05EA \u05D3\u05E3 \u05D0\u05D9\u05E0\u05D8\
  \u05E8\u05E0\u05D8 \u05D6\u05D4 \u05E4\u05E9\u05D5\u05D8 \u05DC\u05E9\u05DC\u05D5\
  \u05E3 \u05EA\u05D5\u05DB\u05DF \u05DE\u05EA\u05D5\u05DA \u05DB\u05EA\u05D5\u05D1\
  \u05EA URL \u05D5\u05DC\u05E9\u05DE\u05D5\u05E8 \u05D0\u05D5\u05EA\u05D5 \u05D1\u05DE\
  \u05E7\u05D5\u05DE\u05D9. \u05EA\u05DB\u05E0\u05D9\u05EA\u05E0\u05D9\u05DD \u05E2\
  \u05D5\u05E9\u05D9\u05DD \u05D0\u05EA \u05D6\u05D4 \u05DC\u05D0\u05D9\u05E1\u05D5\
  \u05E3 \u05E0\u05EA\u05D5\u05E0\u05D9\u05DD, \u05D1\u05D3\u05D9\u05E7\u05D5\u05EA\
  \ \u05D0\u05D5\u05D8\u05D5\u05DE\u05D8\u05D9\u05D5\u05EA, \u05D0\u05D5 \u05E4\u05E9\
  \u05D5\u05D8 \u05DB\u05D3\u05D9 \u05DC\u05D4\u05E9\u05D9\u05D2 \u05D0\u05EA \u05D4\
  \u05EA\u05D5\u05DB\u05DF\u2026"
lastmod: '2024-03-13T22:44:40.046835-06:00'
model: gpt-4-1106-preview
summary: "\u05D4\u05D5\u05E8\u05D3\u05EA \u05D3\u05E3 \u05D0\u05D9\u05E0\u05D8\u05E8\
  \u05E0\u05D8 \u05D6\u05D4 \u05E4\u05E9\u05D5\u05D8 \u05DC\u05E9\u05DC\u05D5\u05E3\
  \ \u05EA\u05D5\u05DB\u05DF \u05DE\u05EA\u05D5\u05DA \u05DB\u05EA\u05D5\u05D1\u05EA\
  \ URL \u05D5\u05DC\u05E9\u05DE\u05D5\u05E8 \u05D0\u05D5\u05EA\u05D5 \u05D1\u05DE\
  \u05E7\u05D5\u05DE\u05D9."
title: "\u05D4\u05D5\u05E8\u05D3\u05EA \u05D3\u05E3 \u05D0\u05D9\u05E0\u05D8\u05E8\
  \u05E0\u05D8"
weight: 42
---

## איך לעשות:
כדי להוריד דף אינטרנט ב-Fish, ניתן להשתמש בפקודות פשוטות כמו `curl` או `wget`. דוגמה:

```Fish Shell
curl https://example.com -o example_page.html
```

זה ישמור את דף האינטרנט של example.com בקובץ בשם example_page.html. אם רוצים לראות את התוכן בטרמינל:

```Fish Shell
curl https://example.com
```

ותקבלו פלט בסגנון:

```
<!doctype html>
<html>
<head>
    <title>Example Domain</title>
...
```

## צלילה לעומק:
בשנות ה-90', עם הופעת האינטרנט, צריך היה דרך להוריד קבצים מרחוק. אז הומצאו פקודות כמו `curl` ו־`wget`. שתיהן עושות את אותו הדבר באופן בסיסי, אבל יש להן אופציות שונות לשימושים מתקדמים. למשל, `curl` היא נפוצה לשליחת בקשות HTTP בצורות שונות, בעוד ש-`wget` ידועה ביכולתה להוריד אתרים שלמים לשימוש לא מקוון. ניתן גם לעשות כמה פעולות עיבוד כמו ניתוח מידע (parsing) של התוכן באמצעות תוכניות אחרות.

## ראו גם:
- מדריך ל-Fish Shell: https://fishshell.com/docs/current/index.html
- מידע מעמיק על `curl`: https://curl.se/docs/
- מידע מעמיק על `wget`: https://www.gnu.org/software/wget/manual/wget.html
- הדרכה על ניתוח HTML ב-Fish באמצעות `pup`: https://github.com/ericchiang/pup
