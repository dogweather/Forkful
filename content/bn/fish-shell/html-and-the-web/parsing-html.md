---
title:                "HTML পার্স করা"
date:                  2024-03-17T18:04:08.394426-06:00
model:                 gpt-4-0125-preview
changelog:
  - 2024-03-17, gpt-4-0125-preview, translated from English
---

{{< edit_this_page >}}

## কি এবং কেন?

HTML পার্স করা মানে HTML কনটেন্ট থেকে ডেটা বা তথ্য এক্সট্রাক্ট করা, যা ওয়েব ডেটা নিয়ে কাজ করার সময় একটি সাধারণ কাজ। প্রোগ্রামাররা এটা করে থাকে ওয়েবসাইট থেকে তথ্য অটোমেটেডভাবে এক্সট্রাক্ট করার জন্য, যেমন ওয়েব স্ক্র্যাপিং, ডেটা মাইনিং, বা অটোমেটেড টেস্টিং এর কাজের জন্য।

## কিভাবে:

Fish shell, মূলত, সরাসরি HTML পার্স করার জন্য ডিজাইন করা হয়নি। তবে, এটি `curl`, `grep`, `sed`, `awk`, বা `pup` বা Python স্ক্রিপ্টে `beautifulsoup` এর মতো বিশেষায়িত টুলগুলির সঙ্গে Unix টুলগুলি একত্রিত করে দুর্দান্ত কাজ করে। নিচে উদাহরণ দেওয়া হল যেগুলি দেখায় যে Fish shell এর মধ্যে থেকে এই টুলগুলি কিভাবে HTML পার্স করার জন্য ব্যবহার করা যায়।

### `curl` এবং `grep` ব্যবহার করে:
HTML কনটেন্ট ফেচ করে এবং লিংকসমূহ থাকা লাইনগুলি এক্সট্রাক্ট করা:

```fish
curl -s https://example.com | grep -oP '(?<=href=")[^"]*'
```

আউটপুট:
```
/page1.html
/page2.html
...
```

### `pup` ব্যবহার করে (HTML পার্স করার জন্য একটি কমান্ড-লাইন টুল):

প্রথমে, নিশ্চিত করুন যে `pup` ইন্সটল করা আছে। তারপর আপনি তার ট্যাগ, আইডি, ক্লাস, ইত্যাদি দ্বারা এলিমেন্টগুলি এক্সট্রাক্ট করতে এটি ব্যবহার করতে পারবেন।

```fish
curl -s https://example.com | pup 'a attr{href}'
```

`grep` উদাহরণের মতো, আউটপুটে `<a>` ট্যাগের href অ্যাট্রিবিউটগুলি তালিকাভুক্ত হবে।

### একটি Python স্ক্রিপ্ট এবং `beautifulsoup` ব্যবহার করে:

যদিও Fish নিজে নেটিভভাবে HTML পার্স করতে পারে না, এটি Python স্ক্রিপ্টের সাথে নির্বিঘ্নে ইন্টিগ্রেট করতে পারে। নিচে একটি সংক্ষিপ্ত উদাহরণ দেওয়া হল যা Python এবং `BeautifulSoup` ব্যবহার করে HTML থেকে টাইটেল এক্সট্রাক্ট করার জন্য। নিশ্চিত করুন যে আপনার Python পরিবেশে `beautifulsoup4` এবং `requests` ইন্সটল করা আছে।

**parse_html.fish**

```fish
function parse_html -a url
    python -c "
import sys
import requests
from bs4 import BeautifulSoup

response = requests.get(sys.argv[1])
soup = BeautifulSoup(response.text, 'html.parser')

titles = soup.find_all('title')

for title in titles:
    print(title.get_text())
" $url
end
```

ব্যবহার:

```fish
parse_html 'https://example.com'
```

আউটপুট:
```
Example Domain
```

এই পদ্ধতিগুলি বিভিন্ন ব্যবহারের ক্ষেত্র এবং জটিলতার মাত্রা সার্ভ করে, সাধারণ কমান্ড-লাইন টেক্সট ম্যানিপুলেশন থেকে শুরু করে Python স্ক্রিপ্টের মধ্যে `beautifulsoup` এর পূর্ণ পার্সিং ক্ষমতা পর্যন্ত। আপনার প্রয়োজন এবং HTML স্ট্রাকচারের জটিলতা অনুসারে, আপনি একটি সোজাসাপ্টা Unix পাইপলাইন বা আরও শক্তিশালী স্ক্রিপ্টিং পদ্ধতি বেছে নিতে পারেন।
