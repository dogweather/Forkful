---
changelog:
- 2024-02-03, gpt-4-0125-preview, translated from English
date: 2024-02-03 19:12:53.217281-07:00
description: "L'analisi di HTML in Rust \xE8 il processo di estrazione dati da documenti\
  \ HTML, essenziale per il web scraping, l'estrazione di dati o la costruzione di\
  \ web\u2026"
lastmod: '2024-03-13T22:44:43.215907-06:00'
model: gpt-4-0125-preview
summary: "L'analisi di HTML in Rust \xE8 il processo di estrazione dati da documenti\
  \ HTML, essenziale per il web scraping, l'estrazione di dati o la costruzione di\
  \ web crawler."
title: Analisi del HTML
weight: 43
---

## Come fare:
Per analizzare HTML in Rust, si utilizza spesso il crate `scraper`, che fornisce un'interfaccia di alto livello per attraversare e manipolare documenti HTML.

Prima, aggiungi `scraper` al tuo `Cargo.toml`:

```toml
[dependencies]
scraper = "0.12.0"
```

Di seguito, ecco un semplice esempio che estrae tutti gli URL dei link da una stringa HTML data:

```rust
extern crate scraper;

use scraper::{Html, Selector};

fn main() {
    let html = r#"
    <html>
    <body>
        <a href="http://example.com/1">Link 1</a>
        <a href="http://example.com/2">Link 2</a>
    </body>
    </html>
    "#;

    let document = Html::parse_document(html);
    let selector = Selector::parse("a").unwrap();

    for element in document.select(&selector) {
        let link = element.value().attr("href").unwrap();
        println!("Trovato link: {}", link);
    }
}
```

Output:

```
Trovato link: http://example.com/1
Trovato link: http://example.com/2
```

In questo esempio, analizziamo un semplice documento HTML per trovare tutti gli elementi `<a>` ed estrarne gli attributi `href`, stampando effettivamente gli URL di tutti i link nel documento. La libreria `scraper` semplifica l'analisi di HTML e la selezione di elementi specifici usando i selettori CSS, rendendola una risorsa ideale per compiti di web scraping in Rust.
